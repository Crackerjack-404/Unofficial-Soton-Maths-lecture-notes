\title{MATH1062: Computational Mathematics}
\author{Shub Das \\ sd2g25@soton.ac.uk}
\date{\today}

\maketitle



\tableofcontents 

\chapter{Intro to Linear Programming and Simplex}

\section{Purpose}


At its heart, Linear programming (LP) is all about min-maxing, with one restriction, namely linearity. So given limited resources and rules, what is the best thing we can do, and `best'  here means often maximising profit, or minimising cost. 

Most common mistakes in LP often come from modelling the wrong thing. Formulating an LP means translating a given situation into: 
\begin{itemize}
    \item An objection 
    \item Decision variables 
    \item Constraints 
\end{itemize}

\section{Objective functions and constraints}

Often what I find with computational heavy subjects is increasing boredom, so in my notes I will attempt to keep some curiosity alive

I will not be going through how to formulate, because that process is very algorithmic and notes do a far better job with their memorable examples of diet. If time wasn't a difficult constraint \footnote{Pun intended, I'd be tempted to come up with my own examples, but for the time being, enjoy some \textbf{\href{https://www.matoles.com/stardew-mip}{Stardew Valley fun}}}

\subsection{Decision variables}

These are the things we control- like how much to buy, allocate, transport, etc. 

\subsection{Objective function}

This is the thing we're trying to optimise or min/max. 


\subsection{Constraints}

These describe what is allowed, and they are usually inequalities like $Ax \leq b$

Geometrically speaking, each constraint takes off part of space, and the \textbf{feasible region} is what's left after applying all the constraints when optimising our objective function 

Always remember non-negativity constraints like $x \geq 0$. They exist because negative quantities often have no interpretation. 

\chapter{Geometry of LP}

Before we define and look at feasible regions, let's step back and think about structures that we have already seen before 


\section{Vectors and dot products}

The objective function in LP is $ c^T x$, which is essentially a dot product. 

Geometrically speaking, $\vec{c}$ is a vector pointing in the direction of increases, and $x$ is just a point in space (a possible solution), $c^T x$ measures how far $x$ lies in the direction of $\vec{c}$

In that view, maximising the objective function just means going as far as possible in the direction of $c$ without breaking the constraints. 


\section{Hyperplanes}

Hyperplanes are basically boundaries that will help us turn algebraic constraints into geometry. And without them, the inequalities are just symbols, and then our $\leq$ don't mean anything spacial. 

With hyperplanes, we will soon come to see that every single constraint will essentially become a wall, and solutions a point, and with that, the feasible region can be represented geometrically. 

\subsection{Intersections}

The feasible region is essentially the set of all points that satisfy every constraint.

However, we also note that each constraint
$$a^T x \le b$$
defines a half-space. 

An equality implies a \textbf{hyperplane}, whereas an \textbf{inequality} implies one side of that hyperplane. 

So another (and more interesting!) way to define a hyperplane is the intersection of all half-space. 

So geometrically speaking: 
\begin{itemize}
    \item 2D $\implies$ polygon
    \item 3D $\implies$ polyhedron
    \item Higher dimensions $\implies$ still a polyhedron, just impossible to draw
\end{itemize}

\subsection{Objective functions} 

The objective function $c^T x = k$ also defines hyperplanes. So all points with the same objective value lie on the hyperplane. And changing $k$ slides the plane in direction $c$. 

So our optimsation problem rephrased is simply to slide a hyperplane until it hits the feasible region for the last time. 

Another point to note, if we want to minimise some function say $f(x)$, that's the same as maximising the negative of it, i.e. 
$$
\max(f(x)) = \max(-f(x)) 
$$
Geometrically again, we have the same feasible region, but objective vector points in the oppostite way. 

\section{Convex}

So, we've discussed how the feasible region is an intersection of half-spaces, and therefore \textbf{convex}

The geometric reason behind optimal LP solutions is that they lie at corners as they are the points where multiple hyperplanes meet. So they are the only locations where a linear objective can be maximised without violating the constraints. 

There is a theorem on this, whose proof can be looked up in a textbook as it's not in the lecture notes 


\section{Slack Variables}

\textbf{Slack variables} do what they say- they represent unused resources in context. 

Think of the constraint $a^Tx \leq b$. This can be rewritten using the slack variable: 
$$
a^Tx + s= b, \quad s \geq 0
$$

Geometrically, they measure how far we are from the boundary. So if $s=0$, the point lies on the hyperplane, and if $s > 0$, the point lies inside the half-space that we defined before. 

\section{Surplus variables}

Similar to slack variables, surplus variables are taken away represent excess resources. 

So we consider the constant $a^Tx \geq b$ and can rewrite it as: 
$$
a^Tx - s = b , \quad s \geq 0
$$

Once again, this is a distance from the hyperplane. 

\section{Why we convert inequalities to equalities}

Once are equations have been turned into equalities and non-negative variables, we can write in the form of $Ax = b$. 

Now, here's the exciting bit, each solution corresponds to a choice of basis vectors, and the corners correspond to a basic feasible solutions. We have turned simplex into a linear algebra problem! 

Look into lecture notes for what it means to write constraints in canonical forms. 

\chapter{The Fundamental Theorem of Linear Programming}

\section{Optimum solutions}

Linear programming has only a small number of possible outcomes, and if an optimal solution exists, it will be at a corner (vertex). 

In other words, we want to imagine, as discussed briefly earlier, the feasible region as a polyhedrom $P$, and look at the 3 cases: 

\begin{itemize}
    \item Infeasible: $P = \emptyset $ This gives us no solutions as it doesn't lie in the solution span
    \item Unbounded: the objective function can go to $+ \infty$ or $- \infty$ along a feasible direction
    \item Optimal: the objective function attains a maximum or a minimum at some point in $P$ 
\end{itemize}

So what LP does is goes from an infinite set of points to finitely many candidates (vertices) and the directions of those feasible directions. 


\section{Augmented Matrices}

We start by formulating LP with lots of inequalities, and want to move to something we can work with. 

So we take our decision variables, $x \in \mathbb{R}$, the inequality constraints, $Ax \leq b$, and the non-negativity constraints, $x \geq 0$ and define our feasible region as a polyhedron $P$ such that: 
$$
P := \set { x \in \mathbb{R^n} : Ax \leq b, x \geq 0}
$$

As looked in the last chapter, we then convert our inequalities to equalities using slack variables: 
$$
Ax + s =b, \quad x \geq 0, s \geq 0
$$

And then we can stack variables into one vector: 
$$
y = \begin{bmatrix}
    x \\ 
    s 
\end{bmatrix} \geq 0, \quad [ A | I ] y = b
$$

And now, if recall from Linear Algebra I, we have this augmented matrix form which we can work with and do fun things like Gaussian elimination. 

\section{Corners and Convex Combinations}

As aforementioned, polyhedra are an intersection of halfspaces, so they are convex, and any non vertex point in a convex set can essentially be written as a convex combination of other points in the set. 

Recall the definition of a convex combination: 
$$
x = \sum_{i=1}^{k} \lambda_i v_i, \quad \lambda_i \geq 0, \quad \sum \lambda_i = 1
$$

And once again we're back at the fundamental theorem, if $x$ is a feasible and not a vertex, it can be expressed as a convex combination of two distinct feasible points. 

With some intuition, the reason why optimum solutions lie at a vertex is because if we're not at a corner, we can move along a line segment inside the polyhedra $P$. Now, along that segment, a linear function can't have a strict interior maximum. So the best value must happen at an endpoint, i.e a vertex. 

Now, if one wants to go further, the lectures suggest looking into \textbf{Wely-Minkowski} theorem for why polyhedra can be described as either an intersection of half-spaces or as a convex combinations of vertices and a cone of rays. 

\section{Complexity}

Now, I won't go into detail about time complexity and the proper Big-0 notation as that can be found in the notes. 

\chapter{The Simplex Algorithm}

\section{Introduction}

In the most simplest (pun intended) way possible, the simplex algorithm walks along the edges of the feasible polyhedron from vertex to vertex, in the direction of the objective function until no more improvements exist. 

The setup and the method can be found in the notes, which I suggest being looked at. What I will cover here is some of the reasoning behind why matrices and things appear. 

Our goal is to maximise some objective function $c^Tx$ subject to $Ax \leq b, x \geq 0$. Let's start with what we know about the geometry. 

\begin{itemize}
    \item Each row of $A$ defines a hyperplane 
    \item The inequalities defines halfspaces 
    \item Their intersection is a polyhedron 
    \item The objective defines a fmaily of parallel hyperplanes
\end{itemize}

And optimisation is just imagine sliding our objective function in direction $c$ until it last touches the feasible region, and we know that if an optimum exists, it happens at a vertex. 

So now, the better question to ask is- how do we systematically move from one vertex to a better one? 

\section{Linear Algebra}

Now, vertices are not just some mystical geometric objects. They correspond to choosing a subset of columns of $A$, which forms and invertible square matrix $B$, so we end up solving a system of linear equations. 

In other words, a vertex is just a particular choice of linearly independent columns. 

The simplex algorithm then, is repeatedly choosing a new basis (i.e. a new invertible set of columns) that improves the objective value. 

To motivate the idea of matrices further, we can't just compute in say 8 dimensions by drawing pretty pictures, we need some sort of algebraic structure. And matrices happen to encode all of those things with them. So when we pivot in the tableau, we are eliminating one set of variables in terms of another. 

\chapter{Gradient Descent}